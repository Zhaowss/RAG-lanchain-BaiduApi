{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px; \n",
    "            color:#150d0a;\n",
    "            margin:10px;\n",
    "            font-size:220%;\n",
    "            text-align:center;\n",
    "            display:fill;\n",
    "            border-radius:20px;\n",
    "            border-width: 5px;\n",
    "            border-style: solid;\n",
    "            border-color: #150d0a;\n",
    "            background-color:#1ee353;\n",
    "            overflow:hidden;\n",
    "            font-weight:500\"> RAG - 智能家居LLM</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./src/llm.jpg\" alt=\"Example Image\" width=\"800\" height=\"500\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div style=\"padding:20px; \n",
    "              color:blue;\n",
    "              margin:10px;\n",
    "              font-size:150%;\n",
    "              text-align:center;\n",
    "              display:fill;\n",
    "              border-radius:20px;\n",
    "              border-width: 5px;\n",
    "              background-color:#eca912;\n",
    "              overflow:hidden;\n",
    "              font-weight:500\">\n",
    "    <b>介绍</b>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个笔记本包含一个使用 LangChain 框架、FAISS 作为向量数据库以及 RAGAS 作为评估指标的完整问答管道。\n",
    "\n",
    "构建 RAG 管道的主要步骤可以总结如下（在文本清理后进行基本的 RAG 管道）：\n",
    "\n",
    "**模型定义**：模型类定义\n",
    "\n",
    "**数据摄取**：从网站加载数据\n",
    "\n",
    "**实例化**：模型 llama2-7b 或 falcon-7b-v2\n",
    "\n",
    "**索引**：使用 RecursiveCharacterTextSplitter 进行分块索引\n",
    "\n",
    "**嵌入**：使用 HuggingFaceBgeEmbeddings BAAI/bge-large-en-v1.5\n",
    "\n",
    "**QA 链检索**：使用 HuggingFacePipeline 和 RetrievalQA\n",
    "\n",
    "**评分**：选择前 k 个最相似的结果\n",
    "\n",
    "**评估**：使用 RAGAS 的 TestsetGenerator 进行评估，包括忠实度、答案相关性、上下文召回率、上下文精确率和答案正确性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div style=\"padding:20px; \n",
    "              color:blue;\n",
    "              margin:10px;\n",
    "              font-size:150%;\n",
    "              text-align:center;\n",
    "              display:fill;\n",
    "              border-radius:20px;\n",
    "              border-width: 5px;\n",
    "              background-color:#eca912;\n",
    "              overflow:hidden;\n",
    "              font-weight:500\">\n",
    "    <b>相关描述介绍</b>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <div style=\"padding:20px; \n",
    "              color:blue;\n",
    "              margin:10px;\n",
    "              font-size:150%;\n",
    "              text-align:center;\n",
    "              display:fill;\n",
    "              border-radius:20px;\n",
    "              border-width: 5px;\n",
    "              background-color:#eca912;\n",
    "              overflow:hidden;\n",
    "              font-weight:500\">\n",
    "    <b>目录</b>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. 依赖](#dep)\n",
    "\n",
    "   * [1.1. 安装](#ins)\n",
    "\n",
    "   * [1.2. 包的导入](#lib)\n",
    "\n",
    "   * [1.3. 设备配置](#drv)\n",
    "\n",
    "   * [1.4. API key设置](#key)\n",
    "   \n",
    "* [2. 模型定义](#mod)  \n",
    "\n",
    "* [3. FAISS RAG Pipeline](#faiss)\n",
    "\n",
    "   * [3.1. 数据加载](#get)        \n",
    "\n",
    "   * [3.2. 索引](#ind)  \n",
    "\n",
    "      * [3.2.1. 实例化模型](#ins)\n",
    "\n",
    "      * [3.2.2. 分割](#split)\n",
    "\n",
    "      * [3.2.3. 嵌入](#emb)\n",
    "\n",
    "      * [3.2.4. 向量存储](#vec)\n",
    "\n",
    "   * [3.3. QA 链检索](#qa)\n",
    "\n",
    "* [4. 模型评估](#eval)\n",
    "\n",
    "   * [4.1. 相似度](#sim)\n",
    "\n",
    "* [5.  LLM智能家居指令控制模型](#steps)\n",
    "\n",
    "   * [5.1.数据加载](#trainllm1)\n",
    "\n",
    "     \n",
    "   * [5.2. 模型微调](#trainllm2)\n",
    "\n",
    "   * [5.3. 模型部署](#trainllm3)\n",
    "      \n",
    "\n",
    "* [6. 智能家居一键式配置](#steps6)\n",
    "\n",
    "\n",
    "   * [6.1. 结构化数据加载](#61)\n",
    "\n",
    "     \n",
    "   * [6.2. 调用大模型进行关键配置提取](#62)\n",
    "\n",
    "   * [6.3. 提取结果展示](#63)\n",
    "\n",
    "* [7. 实时天气数据获取](#steps7)\n",
    "\n",
    "\n",
    "   * [7.1. 结构化数据加载](#71)\n",
    "\n",
    "     \n",
    "   * [7.2. 调用大模型预测分析](#72)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbc2zfNpOzR6"
   },
   "source": [
    "# <font color='289C4E'>1. 依赖 📚<font><a class='anchor' id='dep'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>1.1.  安装 📑<font><a class='anchor' id='ins'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f6bE5-fiRH8w"
   },
   "outputs": [],
   "source": [
    "!pip install -U -qq tiktoken cohere openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IXYKCAEOe_p7"
   },
   "outputs": [],
   "source": [
    "!pip install -U -qq torch==2.1.2 torchvision torchaudio torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3wGdR1H4fAQP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for faiss-gpu\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.2 requires torch==2.1.2, but you have torch 2.3.0 which is incompatible.\n",
      "torchtext 0.16.2 requires torch==2.1.2, but you have torch 2.3.0 which is incompatible.\n",
      "torchvision 0.16.2 requires torch==2.1.2, but you have torch 2.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -qq langchain pypdf faiss-gpu  \n",
    "!pip install -U -qq transformers InstructorEmbedding sentence_transformers  \n",
    "!pip install -U -qq huggingface-hub accelerate bitsandbytes xformers einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BFBYv1aTs67"
   },
   "outputs": [],
   "source": [
    "!pip install -U -qq ragas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7Ye4-KpUJc0"
   },
   "source": [
    "## <font color='289C4E'>1.2. 包的导入 📑<font><a class='anchor' id='lib'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "W7_1dIq8MCdA"
   },
   "outputs": [],
   "source": [
    "# Global\n",
    "import os\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"CURL_CA_BUNDLE\"]=\"\"\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from datasets import DatasetDict, Dataset\n",
    "import json\n",
    "\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "import os\n",
    "from langchain_wenxin.chat_models import ChatWenxin\n",
    "\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain_core.language_models.chat_models import HumanMessage\n",
    "from langchain_community.llms import QianfanLLMEndpoint\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.docstore.document import Document\n",
    "import requests\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import pickle\n",
    "import os\n",
    "import pdb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Ragas\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from ragas import evaluate\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMr1Nh0PWWas"
   },
   "source": [
    "## <font color='289C4E'>1.3. 设备配置 📖<font><a class='anchor' id='drv'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18006,
     "status": "ok",
     "timestamp": 1707335823729,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "-eLEPf3HpRIn",
    "outputId": "e26d2115-baf2-4542-823f-97976ae333ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 查看可用的设备\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "# 指定使用GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryTQSWpDDlvc"
   },
   "source": [
    "## <font color='289C4E'>1.4. API Keys设置 🗝️<font><a class='anchor' id='keys'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jZZ5X6O1BBf_"
   },
   "outputs": [],
   "source": [
    "os.environ[\"QIANFAN_AK\"] = \"cmpZpRZWsuSaO8uuvrPiAeId\"\n",
    "os.environ[\"QIANFAN_SK\"] = \"FmHEECYgpyFLjKqyG09xk9WaoTQ4AZWo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGmy3p0In4QL"
   },
   "source": [
    "# <font color='289C4E'>2. 模型的定义 🧹<font><a class='anchor' id='mod'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJjDmSPyIIJw"
   },
   "source": [
    "这种管道的方法是创建具有所有参数的模型函数，这将允许实例化具有其超参数的对应大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "wFg25SBpdn3M"
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model_name ='wenxin', temperature = 0,\n",
    "                 top_p = 0.95, repetition_penalty = 1.15,\n",
    "                 split_chunk_size = 512, split_overlap = 16, k = 3,\n",
    "                 embeddings_path = \"./faiss_index_hp\",\n",
    "                 persist_directory = \"./faiss-vectordb\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize the Model class with default values and parameters.\n",
    "        :param model_name: Name of the model (default: 'wenxin')\n",
    "        :param temperature: Controls the randomness of the predictions (default: 0)\n",
    "        :param top_p: Top p value for nucleus sampling (default: 0.95)\n",
    "        :param repetition_penalty: Penalty for repeated tokens (default: 1.15)\n",
    "        :param split_chunk_size: Size of chunks to split the input text (default: 800)\n",
    "        :param split_overlap: Overlap between split chunks (default: 0)\n",
    "        :param k: Value for some parameter 'k' (default: 3)\n",
    "        \"\"\"\n",
    "        # 参数\n",
    "        self.model_name = model_name\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.repetition_penalty = repetition_penalty\n",
    "        self.split_chunk_size = split_chunk_size\n",
    "        self.split_overlap = split_overlap\n",
    "        self.embeddings_model_repo = 'BAAI/bge-large-en-v1.5'\n",
    "        self.k = k\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.persist_directory = persist_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义一个pipeline的一个包装类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomQianfanPipeline:\n",
    "    def __init__(self, streaming=True):\n",
    "        self.llm = QianfanLLMEndpoint(streaming=streaming)\n",
    "        self.task = \"text-generation\"  # 添加任务属性\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        if isinstance(inputs, list):\n",
    "            prompt = inputs[0]\n",
    "        else:\n",
    "            prompt = inputs\n",
    "        response = self.llm(prompt)\n",
    "        return [{\"generated_text\": response}]  # 确保返回值是一个包含生成文本的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "-eGtE1a2e2ZU"
   },
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    # Extract the model name from the configuration\n",
    "    model_name = config.model_name\n",
    "    # Dictionary containing model parameters\n",
    "    model_params = {\n",
    "        'wenxin': {\n",
    "            'repo': 'daryl149/llama-2-7b-chat-hf',\n",
    "            'max_len': 2048,\n",
    "            'extra_params': {\n",
    "                'device_map': 'auto',\n",
    "                'torch_dtype': torch.float16,\n",
    "                'low_cpu_mem_usage': True,\n",
    "                'trust_remote_code': True\n",
    "            }\n",
    "        },\n",
    "        'falcon': {\n",
    "            'repo': 'h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2',\n",
    "            'max_len': 1024,\n",
    "            'extra_params': {\n",
    "                'device_map': 'auto',\n",
    "                'torch_dtype': torch.float16,\n",
    "                'low_cpu_mem_usage': True,\n",
    "                'trust_remote_code': True\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Check if the provided model name exists in the predefined model parameters\n",
    "    if model_name in model_params:\n",
    "        # Get the parameters for the specified model\n",
    "        params = model_params[model_name]\n",
    "        model_repo = params['repo']\n",
    "\n",
    "        # Extract any additional parameters specific to the model\n",
    "        extra_params = params.get('extra_params', {})\n",
    "\n",
    "        # Instantiate a tokenizer based on the model repository and extra parameters\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo, **extra_params)\n",
    "\n",
    "        model= CustomQianfanPipeline(streaming=True)\n",
    "        # Get the maximum length for the model\n",
    "        max_len = params['max_len']\n",
    "    else:\n",
    "        # Raise an error if the provided model is not implemented in the dictionary\n",
    "        raise ValueError(\"The provided model is not implemented.\")\n",
    "\n",
    "    # Return the instantiated tokenizer, model, and maximum length\n",
    "    return tokenizer, model, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyOQAgEWdLOd"
   },
   "source": [
    "# <font color='289C4E'>3. FAISS RAG Pipeline 📳<font><a class='anchor' id='faiss'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"src/output.gif\" alt=\"Animated GIF\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7VWJpaZG_oZ"
   },
   "source": [
    "## <font color='289C4E'>3.1. 数据加载 🎡<font><a class='anchor' id='get'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_8tmPMFHaqu"
   },
   "source": [
    "第一步是获取我们的数据。我们将使用 WebBaseLoader，并选择要加载的网站。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "AFwejc8YCWMC"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "loader = WebBaseLoader(\n",
    "    \"http://www.sohu.com/a/681843047_121733165\"\n",
    ")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "FF09LxaoDeKi"
   },
   "outputs": [],
   "source": [
    "# Save the loaded documents using pickle\n",
    "\n",
    "with open('/loaded_documents.pkl', 'wb') as file:\n",
    "    pickle.dump(documents, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "iZt7vduFDhMa"
   },
   "outputs": [],
   "source": [
    "# Load the saved documents\n",
    "\n",
    "with open('/loaded_documents.pkl', 'rb') as file:\n",
    "    documents = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXiSJzu2KlPD"
   },
   "source": [
    "## <font color='289C4E'>3.2. 索引 🌊<font><a class='anchor' id='ind'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-xCQ2NXK2LF"
   },
   "source": [
    "为了创建索引，需要遵循以下几个步骤：\n",
    "\n",
    "- 选择一种分割方法及其超参数：我们将使用**RecursiveCharacterTextSplitter**。该方法递归地尝试通过不同的字符进行分割，以找到合适的分割点。\n",
    "\n",
    "- 选择嵌入模型：在我们的案例中，选择**BAAI/bge-large-en-v1.5**。\n",
    "\n",
    "- 选择一个向量存储：**FAISS**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdGjn3lxIj3M"
   },
   "source": [
    "### <font color='289C4E'>3.2.1. 实例化模型 🔠<font><a class='anchor' id='ins'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPVTPjHUIq37"
   },
   "source": [
    "We have to instatiate the model in order to pass the corresponding hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "4b0cec060c354c17bd42ea962ee82908",
      "6e5a79fd5cef460a9aa4e0e1a357005c",
      "981d063cbad446a383c0f61a7fd8c122",
      "aade9e1a132a4fc694e1edc22f804690",
      "bb64f83fe1924062bf10c1f54c1e4fbf",
      "000833995fa54070b6a2386e469e887d",
      "fb28f79da8f244d8bbc342183cabcbbd",
      "88aa1c2e504a49b08c95dcca76b008ce",
      "bf036d627906439383d8605417385c17",
      "fa438f0e115e444d8935fb6d9fea1f32",
      "52f2a93bd339471fb2174073ef900df7"
     ]
    },
    "executionInfo": {
     "elapsed": 8635,
     "status": "ok",
     "timestamp": 1707336592628,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "jMYpOoX1IjRr",
    "outputId": "a5bae5c8-994a-4986-f81f-b01eb663d62f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the Model Class and get the model\n",
    "my_faiss_model = Model(model_name=\"wenxin\",\n",
    "                       embeddings_path = \"/faiss_index_hp\",\n",
    "                       persist_directory = \"./faiss-vectordb\")\n",
    "   \n",
    "tokenizer, model_faiss, max_len= get_model(config=my_faiss_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "189X8HGRoHz8"
   },
   "source": [
    "### <font color='289C4E'>3.2.2 分割 🪓<font><a class='anchor' id='split'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1707336596686,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "Cfpu4mJs2fS9",
    "outputId": "84e7eeb2-3ee5-4e06-ac6a-085fd89f994a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 4\n",
      "Number of Pages: 1\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a RecursiveCharacterTextSplitter using parameters from 'my_model'\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=my_faiss_model.split_chunk_size,  # Set the size of each text chunk\n",
    "    chunk_overlap=my_faiss_model.split_overlap   # Set the overlap between consecutive chunks\n",
    ")\n",
    "\n",
    "# Split the documents into smaller texts using the text splitter\n",
    "splitted_text = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the number of resulting text chunks\n",
    "print(f'Number of Chunks: {len(splitted_text)}')\n",
    "\n",
    "# Print the number of original pages/documents\n",
    "print(f'Number of Pages: {len(documents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCaM1ubXo82C"
   },
   "source": [
    "### <font color='289C4E'>3.2.3. 嵌入 🪟<font><a class='anchor' id='emb'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "FwKM4zAXo8Mi"
   },
   "outputs": [],
   "source": [
    "# Download embeddings model\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name = my_faiss_model.embeddings_model_repo,\n",
    "    model_kwargs = {\"device\": \"cpu\"},\n",
    "    encode_kwargs = {\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tj2jlpoLOLiW"
   },
   "source": [
    "### <font color='289C4E'>3.2.4. 向量存储 🗂️<font><a class='anchor' id='vec'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oz91Afv3NUam"
   },
   "outputs": [],
   "source": [
    "# Create the vector store\n",
    "\n",
    "faiss_vectordb = FAISS.from_documents(\n",
    "                documents = splitted_text,\n",
    "                embedding = embeddings\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf7axylTRTsJ"
   },
   "source": [
    "## <font color='289C4E'>3.3. QA链检索 🚒<font><a class='anchor' id='qa'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./src/llm2.jpg\" alt=\"Example Image\" width=\"800\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9lJml0vYkt6"
   },
   "source": [
    "下一步，我们需要创建我们的检索管道，为了将提示与额外的上下文结合起来，我们需要准备一个提示模板。可以从下面显示的提示模板轻松定制提示。该管道将使用**HuggingFacePipeline**创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "executionInfo": {
     "elapsed": 14905,
     "status": "ok",
     "timestamp": 1707342488996,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "3l-LT34TeRCn",
    "outputId": "5440aa0b-d932-42a2-943e-0d30385cf892"
   },
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=model_faiss)\n",
    "\n",
    "# Corvert the vector store in a retriever\n",
    "retriever = faiss_vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": my_faiss_model.k})\n",
    "# Set prompt template\n",
    "template = \"\"\"你是一位智能家居助手，可以帮助我控制家居生活并回答问题。\n",
    "根据检索的上下文来回答问题，如果不知道答案，只需说明不知道。\n",
    "\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'智能家居健康配置包括健康家居监测设备和智能家电。智能家电包括智能空调、智能冰箱、智能洗衣机、智能灯光等，能够通过智能化技术提高居住舒适度，提供更贴心的服务。健康家居监测设备包括智能体重秤、智能手环、智能血压计等，能够监测身体健康状况，提供健康建议和预警。\\n\\n您可以根据您的需求选择合适的智能家居控制系统和智能家电，以实现家居健康智能化配置。同时，您也可以关注一些智能家居品牌和平台，了解更多有关智能家居健康配置的信息。'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the question\n",
    "question = \"请帮我提供家居健康智能配置\"\n",
    "# Callback: helps to show and manage the output\n",
    "handler =  StdOutCallbackHandler()\n",
    "\n",
    "# Initializing a combined QA chain\n",
    "qa_combined_chain = RetrievalQA.from_chain_type(\n",
    "                    llm=llm,\n",
    "                    chain_type_kwargs = {\"prompt\": prompt},\n",
    "                    retriever=retriever,\n",
    "                    callbacks=[handler],\n",
    "                    return_source_documents=True)\n",
    "\n",
    "# Initialize the query\n",
    "response = qa_combined_chain({\"query\": question, \"context\": retriever})\n",
    "\n",
    "# Print response\n",
    "response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707342488996,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "oH-KXFMbQZGq",
    "outputId": "ef86e91a-1457-42e2-9a64-42dfe61392b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'http://www.sohu.com/a/681843047_121733165', 'title': '你应该了解的智能家居控制系统_智能化_设备_用户', 'description': '\\n 华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。 京东智能家居控制系统：京东公司推出…', 'language': 'No language found.'}, page_content='你应该了解的智能家居控制系统_智能化_设备_用户\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n新闻\\n体育\\n汽车\\n房产\\n旅游\\n教育\\n时尚\\n科技\\n财经\\n娱乐\\n更多\\n\\n母婴\\n健康\\n历史\\n军事\\n美食\\n文化\\n星座\\n专题\\n游戏\\n搞笑\\n动漫\\n宠物\\n\\n\\n\\n\\n\\n\\n无障碍\\n\\n关怀版\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n爱科技er\\n\\n\\n\\n文章\\n总阅读\\n\\n\\n\\n\\n\\n\\n查看TA的文章>\\n\\n \\n\\n评论\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    你应该了解的智能家居控制系统                \\n\\n\\n\\n\\n                        2023-06-03 22:25        \\n发布于：北京市\\n\\n\\n\\n\\n智能家居控制系统是一种智能化的家居系统，通过集成各种智能设备和互联网技术，实现对家居环境的远程控制和智能化管理。它能够提高生活质量，提升居住舒适度，提高居家安全性和便利性，成为未来智慧家居的重要组成部分。\\n\\n智能家居控制系统包括家庭安防、照明系统、智能家电、温控系统、音视频系统等多个领域。以下是几个相对成熟的智能家居控制系统。'),\n",
       " Document(metadata={'source': 'http://www.sohu.com/a/681843047_121733165', 'title': '你应该了解的智能家居控制系统_智能化_设备_用户', 'description': '\\n 华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。 京东智能家居控制系统：京东公司推出…', 'language': 'No language found.'}, page_content='小米智能家居控制系统：小米公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，用户体验良好。\\n华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。\\n京东智能家居控制系统：京东公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种品牌的智能设备，用户体验良好。\\n深度智能家居控制系统：深度公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有较高的智能化程度。\\n\\n这些智能家居控制系统都具有良好的用户体验、稳定性和可扩展性，能够满足不同用户的需求。未来中国的智能家居控制系统市场将继续呈现快速发展的趋势，为人们创造更加智能、便捷和舒适的生活环境。近期有装修和房屋改造需求的，可以考虑上一套智能控制系统。\\n关注我，了解更多科技前沿进展返回搜狐，查看更多 \\n\\n责任编辑：\\n\\n\\n平台声明：该文观点仅代表作者本人，搜狐号系信息发布平台，搜狐仅提供信息存储空间服务。'),\n",
       " Document(metadata={'source': 'http://www.sohu.com/a/681843047_121733165', 'title': '你应该了解的智能家居控制系统_智能化_设备_用户', 'description': '\\n 华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。 京东智能家居控制系统：京东公司推出…', 'language': 'No language found.'}, page_content='Apple HomeKit：苹果公司推出的智能家居控制系统，能够通过iPhone、iPad等苹果设备来控制智能家居设备，具有高度的用户友好性和稳定性。\\nAmazon Alexa：亚马逊公司推出的智能语音助手，能够通过语音指令控制智能家居设备，支持多种品牌的智能设备，用户体验优秀。\\nGoogle Home：谷歌公司推出的智能家居控制系统，能够通过语音指令控制智能家居设备，支持多种品牌的智能设备，具有较高的智能化程度。\\nSamsung SmartThings：三星公司推出的智能家居控制系统，能够通过手机应用或语音指令控制智能家居设备，支持多种品牌的智能设备，具有较高的兼容性和可扩展性。\\n\\n中国的智能家居控制系统市场也在不断发展，以下是几款比较知名的智能家居控制系统。')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='289C4E'>4. 模型评估 ❓<font><a class='anchor' id='eval'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_K2-ZYRWfK7-"
   },
   "source": [
    "## <font color='289C4E'>4.1. 相似度 🤼‍♂️<font><a class='anchor' id='sim'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6PqjCrdOVdl"
   },
   "source": [
    "FAISS有一些特定的方法用于检查相似度。其中之一是 **similarity_search_with_score**（搜索与查询向量最相似的前k个向量），它不仅可以返回文档，还可以返回查询向量与这些文档之间的距离分数。返回的距离分数是L2距离。因此，较接近0的较低分数表示相似度更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707345302439,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "cqpgNTRdX5Y7",
    "outputId": "ac0e8eb1-fcc9-401f-f4b2-0140008cce86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: http://www.sohu.com/a/681843047_121733165, Score: 0.4059630036354065\n",
      "Source: http://www.sohu.com/a/681843047_121733165, Score: 0.41701382398605347\n",
      "Source: http://www.sohu.com/a/681843047_121733165, Score: 0.5442841053009033\n"
     ]
    }
   ],
   "source": [
    "### Testing Similarity Search\n",
    "\n",
    "# Set the question\n",
    "question = \"请帮我提供家居健康智能配置\"\n",
    "\n",
    "results_with_scores = faiss_vectordb.similarity_search_with_score(question, k = my_faiss_model.k)\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    metadata = doc.metadata if hasattr(doc, 'metadata') else None\n",
    "    source = metadata.get('source') if metadata else None\n",
    "    # title = metadata.get('title') if metadata else None\n",
    "\n",
    "    print(f\"Source: {source}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707345304057,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "okIuqlPlfrto",
    "outputId": "7c7064d0-8753-40b6-c9b4-820d308edd67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'http://www.sohu.com/a/681843047_121733165', 'title': '你应该了解的智能家居控制系统_智能化_设备_用户', 'description': '\\n 华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。 京东智能家居控制系统：京东公司推出…', 'language': 'No language found.'}, page_content='你应该了解的智能家居控制系统_智能化_设备_用户\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n新闻\\n体育\\n汽车\\n房产\\n旅游\\n教育\\n时尚\\n科技\\n财经\\n娱乐\\n更多\\n\\n母婴\\n健康\\n历史\\n军事\\n美食\\n文化\\n星座\\n专题\\n游戏\\n搞笑\\n动漫\\n宠物\\n\\n\\n\\n\\n\\n\\n无障碍\\n\\n关怀版\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n爱科技er\\n\\n\\n\\n文章\\n总阅读\\n\\n\\n\\n\\n\\n\\n查看TA的文章>\\n\\n \\n\\n评论\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                    你应该了解的智能家居控制系统                \\n\\n\\n\\n\\n                        2023-06-03 22:25        \\n发布于：北京市\\n\\n\\n\\n\\n智能家居控制系统是一种智能化的家居系统，通过集成各种智能设备和互联网技术，实现对家居环境的远程控制和智能化管理。它能够提高生活质量，提升居住舒适度，提高居家安全性和便利性，成为未来智慧家居的重要组成部分。\\n\\n智能家居控制系统包括家庭安防、照明系统、智能家电、温控系统、音视频系统等多个领域。以下是几个相对成熟的智能家居控制系统。'),\n",
       "  0.405963),\n",
       " (Document(metadata={'source': 'http://www.sohu.com/a/681843047_121733165', 'title': '你应该了解的智能家居控制系统_智能化_设备_用户', 'description': '\\n 华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。 京东智能家居控制系统：京东公司推出…', 'language': 'No language found.'}, page_content='小米智能家居控制系统：小米公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，用户体验良好。\\n华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。\\n京东智能家居控制系统：京东公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种品牌的智能设备，用户体验良好。\\n深度智能家居控制系统：深度公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有较高的智能化程度。\\n\\n这些智能家居控制系统都具有良好的用户体验、稳定性和可扩展性，能够满足不同用户的需求。未来中国的智能家居控制系统市场将继续呈现快速发展的趋势，为人们创造更加智能、便捷和舒适的生活环境。近期有装修和房屋改造需求的，可以考虑上一套智能控制系统。\\n关注我，了解更多科技前沿进展返回搜狐，查看更多 \\n\\n责任编辑：\\n\\n\\n平台声明：该文观点仅代表作者本人，搜狐号系信息发布平台，搜狐仅提供信息存储空间服务。'),\n",
       "  0.41701382),\n",
       " (Document(metadata={'source': 'http://www.sohu.com/a/681843047_121733165', 'title': '你应该了解的智能家居控制系统_智能化_设备_用户', 'description': '\\n 华为智能家居控制系统：华为公司推出的智能家居控制系统，能够实现对智能家电、照明、安防等设备的远程控制和管理，支持多种语音助手和智能设备，具有高度的安全性和可靠性。 京东智能家居控制系统：京东公司推出…', 'language': 'No language found.'}, page_content='Apple HomeKit：苹果公司推出的智能家居控制系统，能够通过iPhone、iPad等苹果设备来控制智能家居设备，具有高度的用户友好性和稳定性。\\nAmazon Alexa：亚马逊公司推出的智能语音助手，能够通过语音指令控制智能家居设备，支持多种品牌的智能设备，用户体验优秀。\\nGoogle Home：谷歌公司推出的智能家居控制系统，能够通过语音指令控制智能家居设备，支持多种品牌的智能设备，具有较高的智能化程度。\\nSamsung SmartThings：三星公司推出的智能家居控制系统，能够通过手机应用或语音指令控制智能家居设备，支持多种品牌的智能设备，具有较高的兼容性和可扩展性。\\n\\n中国的智能家居控制系统市场也在不断发展，以下是几款比较知名的智能家居控制系统。'),\n",
       "  0.5442841)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxoVc0BmZVaA"
   },
   "source": [
    "另一个指标是 **similarity_search_with_relevance_scores**。该指标的范围为0到1。因此，接近1的较高分数表示相似度更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 526,
     "status": "ok",
     "timestamp": 1707345309010,
     "user": {
      "displayName": "Benito Martin",
      "userId": "03469146416851029106"
     },
     "user_tz": -60
    },
    "id": "g6-EaE_NN-Tq",
    "outputId": "49a6a53b-35b7-4272-8039-cbd85dd51015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: http://www.sohu.com/a/681843047_121733165, Score: 0.712940807218545\n",
      "Source: http://www.sohu.com/a/681843047_121733165, Score: 0.7051266972109282\n",
      "Source: http://www.sohu.com/a/681843047_121733165, Score: 0.6151330182496784\n"
     ]
    }
   ],
   "source": [
    "question = \"请帮我提供家居健康智能配置\"\n",
    "\n",
    "results_with_scores = faiss_vectordb.similarity_search_with_relevance_scores(question, k = my_faiss_model.k)\n",
    "\n",
    "\n",
    "for doc, score in results_with_scores:\n",
    "    metadata = doc.metadata if hasattr(doc, 'metadata') else None\n",
    "    source = metadata.get('source') if metadata else None\n",
    "    # title = metadata.get('title') if metadata else None\n",
    "\n",
    "    print(f\"Source: {source}, Score: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='289C4E'>5. LLM智能家居指令控制模型 📈<font><a class='anchor' id='steps'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>5.1. 数据加载 🤼‍♂️<font><a class='anchor' id='trainllm1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file=\"D:\\\\Desktop\\\\rag+langchain\\\\src\\\\dataset_info.json\"\n",
    "\n",
    "def load_json_dataset(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "ds=load_json_dataset(dataset_file)\n",
    "processed_data = {\n",
    "    'instruction': [item['instruction'] for item in ds],\n",
    "    'input': [item['input'] for item in ds],\n",
    "    'output': [item['output'] for item in ds]\n",
    "}\n",
    "ds= Dataset.from_dict(processed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>5.2. 模型微调 🤼‍♂️<font><a class='anchor' id='trainllm2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./src/lora.png\" alt=\"Example Image\" width=\"800\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEFT（Parameter-Efficient Fine-Tuning）\n",
    "\n",
    "**基本原理**:\n",
    "- **参数高效微调**：PEFT 是一种参数高效的微调方法，旨在通过调整模型的部分参数而非全部参数来实现对新任务的适应。PEFT 的目标是最大化微调的效率和效果，同时最小化所需的计算资源和存储空间。\n",
    "- **常见方法**:\n",
    "  - **LoRA**：通过低秩分解来减少需要更新的参数。\n",
    "  - **Adapter**：在模型的特定层之间插入小型适配器模块，仅微调这些模块的参数。\n",
    "  - **Prefix Tuning**：对输入序列的前缀部分进行参数微调，使得模型能够适应新的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA 微调\n",
    "\n",
    "**基本原理**:\n",
    "- **低秩分解**：LoRA 微调通过将预训练模型的权重矩阵 \\(W\\) 分解为两个低秩矩阵 \\(A\\) 和 \\(B\\)，即 \\(W = W_0 + \\Delta W\\)，其中 \\(\\Delta W = A \\cdot B\\)。其中，\\(W_0\\) 是预训练模型的原始权重矩阵，\\(\\Delta W\\) 是需要学习的微调部分。通过选择合适的低秩矩阵 \\(A\\) 和 \\(B\\)，可以大幅减少微调参数的数量。\n",
    "- **训练过程**：在微调过程中，仅更新低秩矩阵 \\(A\\) 和 \\(B\\)，而保持原始权重矩阵 \\(W_0\\) 不变。这种方法能够在减少计算和存储开销的情况下，实现对模型的有效微调。\n",
    "\n",
    "### 实现方式\n",
    "\n",
    "1. **LoRA**:\n",
    "   - 将原始权重矩阵 \\(W\\) 表示为 \\(W_0 + \\Delta W\\)，其中 \\(\\Delta W = A \\cdot B\\)。\n",
    "   - 在微调过程中，保持 \\(W_0\\) 不变，仅更新 \\(A\\) 和 \\(B\\) 以适应新任务。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/bloom-1b4-zh\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Langboat/bloom-1b4-zh\", low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(task_type=TaskType.CAUSAL_LM, target_modules=\".*\\.1.*query_key_value\", modules_to_save=[\"word_embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./chatbot\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 256\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"]]).strip() + \"\\n\\nAssistant: \")\n",
    "    response = tokenizer(example[\"output\"] + tokenizer.eos_token)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3071.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_ds,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 10/160 [01:53<28:04, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4742, 'grad_norm': 3.694650888442993, 'learning_rate': 4.6875e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 20/160 [03:46<25:55, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.145, 'grad_norm': 3.5705406665802, 'learning_rate': 4.375e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 30/160 [05:41<25:05, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7944, 'grad_norm': 2.884162425994873, 'learning_rate': 4.0625000000000005e-05, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 40/160 [07:37<22:58, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4852, 'grad_norm': 2.2281594276428223, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 50/160 [09:28<20:29, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1844, 'grad_norm': 2.1727488040924072, 'learning_rate': 3.4375e-05, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 60/160 [11:20<18:12, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9464, 'grad_norm': 2.667053699493408, 'learning_rate': 3.125e-05, 'epoch': 3.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 70/160 [13:15<17:31, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8295, 'grad_norm': 2.311216115951538, 'learning_rate': 2.8125000000000003e-05, 'epoch': 4.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 80/160 [15:10<15:18, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6212, 'grad_norm': 1.837109923362732, 'learning_rate': 2.5e-05, 'epoch': 4.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 90/160 [17:06<13:18, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5747, 'grad_norm': 2.1625804901123047, 'learning_rate': 2.1875e-05, 'epoch': 5.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 100/160 [19:00<11:23, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4673, 'grad_norm': 1.7915154695510864, 'learning_rate': 1.8750000000000002e-05, 'epoch': 6.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 110/160 [20:54<09:20, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4274, 'grad_norm': 2.214961528778076, 'learning_rate': 1.5625e-05, 'epoch': 6.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 120/160 [22:49<07:43, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.416, 'grad_norm': 1.8750005960464478, 'learning_rate': 1.25e-05, 'epoch': 7.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 130/160 [24:43<05:51, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3404, 'grad_norm': 1.3083585500717163, 'learning_rate': 9.375000000000001e-06, 'epoch': 8.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 140/160 [26:34<03:43, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3924, 'grad_norm': 1.7557199001312256, 'learning_rate': 6.25e-06, 'epoch': 8.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 150/160 [28:30<01:54, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3688, 'grad_norm': 1.3536432981491089, 'learning_rate': 3.125e-06, 'epoch': 9.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [30:21<00:00, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3224, 'grad_norm': 1.638658881187439, 'learning_rate': 0.0, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [30:22<00:00, 11.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1822.9843, 'train_samples_per_second': 0.708, 'train_steps_per_second': 0.088, 'train_loss': 0.9243620336055756, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=0.9243620336055756, metrics={'train_runtime': 1822.9843, 'train_samples_per_second': 0.708, 'train_steps_per_second': 0.088, 'total_flos': 777462212395008.0, 'train_loss': 0.9243620336055756, 'epoch': 9.922480620155039})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>5.3. 集成部署 🤼‍♂️<font><a class='anchor' id='trainllm3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: 开启美的空调\\n\\nAssistant: 开启美的空调\\nThe Assistant has to wait until the next power outage, or may not switch on if the power is back on.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model\n",
    "ipt = tokenizer(\"Human: {}\\n{}\".format(\"开启美的空调\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "tokenizer.decode(model.generate(**ipt, max_length=128, do_sample=True)[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='289C4E'>6. LLM智能家居一键式配置 📈<font><a class='anchor' id='steps6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./src/llm4.png\" alt=\"Example Image\" width=\"800\" height=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "流程设计\n",
    "PDF 文件读取：\n",
    "\n",
    "使用 Python 库（如 PyPDF2、pdfplumber）读取 PDF 文件内容，并将其转换为纯文本格式。\n",
    "文本分割：\n",
    "\n",
    "将转换后的文本按段落或页面进行分割，以便逐步处理长文档内容。\n",
    "使用 LangChain 的 RecursiveCharacterTextSplitter 进行文本分割。\n",
    "嵌入生成：\n",
    "\n",
    "使用预训练的嵌入模型（如 BAAI/bge-large-en-v1.5）将分割后的文本转换为向量表示。\n",
    "向量存储：\n",
    "\n",
    "将生成的文本向量存储在向量数据库中（如 FAISS），以便后续的快速查询和相似度计算。\n",
    "内容抽取：\n",
    "\n",
    "根据查询需求，使用向量存储库中存储的文本向量进行相似度搜索，提取与查询相关的文本内容。\n",
    "利用 LangChain 的 LLM 模型进行自然语言处理，进一步提取和生成所需的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>6.1. 结构化数据加载 🤼‍♂️<font><a class='anchor' id='61'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path=\"D:\\\\Desktop\\\\rag+langchain\\\\pdf\\\\\"\n",
    "def get_pdf_data(file_path, num_pages = 1):\n",
    "  reader = PdfReader(source_path+file_path)\n",
    "  full_doc_text = \"\"\n",
    "  for page in range(len(reader.pages)):\n",
    "    current_page = reader.pages[page]\n",
    "    text = current_page.extract_text()\n",
    "    full_doc_text += text\n",
    "\n",
    "\n",
    "  return Document(\n",
    "        page_content=full_doc_text,\n",
    "        metadata = {\"source\": file_path}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_docs():\n",
    "    return [get_pdf_data(file) for file in os.listdir(\"D:\\\\Desktop\\\\rag+langchain\\\\pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_index(source_docs):\n",
    "    source_chunks = []\n",
    "    splitter = CharacterTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=0)\n",
    "\n",
    "    for source in source_docs:\n",
    "        for chunk in splitter.split_text(source.page_content):\n",
    "            source_chunks.append(Document(page_content=chunk, metadata=source.metadata))\n",
    "    with open(\"search_index.pickle\", \"wb\") as f:\n",
    "        pickle.dump(FAISS.from_documents(source_chunks, embeddings), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>6.2. 调用大模型进行关键配置提取 🤼‍♂️<font><a class='anchor' id='62'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./src/llm3.png\" alt=\"Example Image\" width=\"800\" height=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_with_sources_chain(llm,verbose=False, chain_type=\"stuff\")\n",
    "def print_answer(question):\n",
    "    with open(\"search_index.pickle\", \"rb\") as f:\n",
    "        search_index = pickle.load(f)\n",
    "    print(\n",
    "        chain(\n",
    "            {\n",
    "                \"input_documents\": search_index.similarity_search(question, k=3),\n",
    "                \"question\": question,\n",
    "            },\n",
    "            return_only_outputs=True,\n",
    "        )[\"output_text\"]\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = source_docs()\n",
    "search_index(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>6.3.抽取结果展示 🤼‍♂️<font><a class='anchor' id='63'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "家居常见配置主要包括空调、加湿器、照明、安防系统等智能家居设备，以下是常见配置参数：\n",
      "\n",
      "* 空调：温度设置范围为夏季的24°C至冬季的20°C，模式包括制冷、制热、除湿、送风，风速分为自动、低、中、高，风向可调节，具有定时开关功能。\n",
      "* 加湿器：湿度设置范围为40%-60%（建议舒适湿度），模式包括低、中、高、自动，水箱容量从2L到6L不等，具有定时开关功能和调节雾量大小的功能。\n",
      "* 照明：亮度可从0%-100%调节，色温从2700K的暖光到6500K的冷光调节，具有阅读模式、休闲模式、夜灯模式等不同的模式，并可实现定时开关功能。同时，智能照明设备通常支持语音控制和手机APP控制。\n",
      "* 安防系统：包括摄像头、报警系统和存储功能。摄像头分辨率可达1080P或4K，具备红外夜视功能和运动检测报警功能。报警系统可以本地存储或云存储，并支持手机APP远程监控。\n",
      "* 其他设备：包括智能门锁和智能音箱等。智能门锁支持指纹解锁、密码解锁、卡片解锁和手机APP解锁等多种方式，安全等级从C级到A级不等，并具有防撬报警和低电量报警等功能。智能音箱支持主流的语音助手，如Amazon Alexa、Google Assistant和Apple Siri，具有高保真音质和360°全向音频，并支持Wi-Fi和蓝牙连接。\n",
      "\n",
      "以上设备是常见的智能家居配置，并没有具体提到Michael Jackson相关的配置信息。\n",
      "\n",
      "SOURCES: main.pdf\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  print_answer(\"question=家居常见配置\") # your question here\n",
    "except Exception as e:\n",
    "  print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='289C4E'>7. 实时天气数据获取 📈<font><a class='anchor' id='steps7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>7.1.网页实时数据提取 🤼‍♂️<font><a class='anchor' id='71'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature: 34°, Temperature_last: 24°\n"
     ]
    }
   ],
   "source": [
    "def get_weather_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # 这里以某个具体网站的天气信息为例\n",
    "    weather = soup.find('div', class_='c-city-weather-forecast')\n",
    "    temperature = weather.find('span', class_='temp').text\n",
    "    temperature_last = weather.find('span', class_='temp last').text\n",
    "\n",
    "    return temperature, temperature_last\n",
    "\n",
    "weather_url = 'https://www.qweather.com/weather/beijing-101010100.html'\n",
    "temperature, weather = get_weather_data(weather_url)\n",
    "print(f\"Temperature: {temperature}, Temperature_last: {weather}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='289C4E'>7.2.调用大模型预测分析 🤼‍♂️<font><a class='anchor' id='72'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据当前温度和最终温度的差异，我为您生成了一份详细的天气报告预测：\n",
      "\n",
      "天气概述：\n",
      "根据当前的温度数据，预计未来的天气将会出现明显的降温。当前的气温为34°，而最终的气温预计为24°。这种气温下降可能会带来一些不同的天气变化，例如可能会影响人们的户外活动和计划。\n",
      "\n",
      "天气变化分析：\n",
      "\n",
      "* 风力：如果气温下降，风力可能会增强。请注意保护您的财物，避免在强风中行走或骑车。\n",
      "* 湿度：湿度的变化可能会影响您的呼吸和健康。如果您有呼吸问题或过敏症状，请注意保持室内空气流通。\n",
      "* 衣物建议：由于气温下降，建议您携带一些保暖衣物，如厚外套、毛衣和帽子。同时，保持水分摄入，以应对可能的干燥天气。\n",
      "* 防晒措施：虽然气温下降，但请注意避免过度暴露在阳光下。防晒霜、遮阳帽和太阳眼镜等防晒用品是必要的。\n",
      "\n",
      "总结：\n",
      "根据当前气温和最终气温的差异，我建议您关注天气预报以了解未来的天气变化。根据预测，风力可能会增强，湿度可能会有所变化。请注意保护您的财物，并携带适当的衣物和防晒用品。同时，保持水分摄入以应对可能的干燥天气。希望这些信息对您有所帮助！\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "# 定义LangChain\n",
    "prompt_template = PromptTemplate(template=\"当前的天气温度是 {temperature} 最终的天气温度是 {weather}. 生成详细的天气报告预测的.\", input_variables=[\"temperature\", \"weather\"])\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# 生成天气报告\n",
    "def generate_weather_report(temperature,  weather):\n",
    "    weather_report = chain.run({\"temperature\": temperature, \"weather\":  weather})\n",
    "    return weather_report\n",
    "\n",
    "weather_report = generate_weather_report(temperature, weather)\n",
    "print(weather_report)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000833995fa54070b6a2386e469e887d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0758dc787b5041329dfe383947fa0ab9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d682dc25ea34d7bb8c91d059c3d956d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34af9b8435ff44f7bc08fb24fd1cb1c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2926d00583842c488ecae1f437dcc02",
      "placeholder": "​",
      "style": "IPY_MODEL_2d682dc25ea34d7bb8c91d059c3d956d",
      "value": "Evaluating: 100%"
     }
    },
    "36547c9fb7b2492fa07194869fdf199e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f98ee9b26db42e087c7dec99caf680c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b0cec060c354c17bd42ea962ee82908": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e5a79fd5cef460a9aa4e0e1a357005c",
       "IPY_MODEL_981d063cbad446a383c0f61a7fd8c122",
       "IPY_MODEL_aade9e1a132a4fc694e1edc22f804690"
      ],
      "layout": "IPY_MODEL_bb64f83fe1924062bf10c1f54c1e4fbf"
     }
    },
    "52f2a93bd339471fb2174073ef900df7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5767b48d8d4742949f60285bb20f353b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e5a79fd5cef460a9aa4e0e1a357005c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_000833995fa54070b6a2386e469e887d",
      "placeholder": "​",
      "style": "IPY_MODEL_fb28f79da8f244d8bbc342183cabcbbd",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "780bec5f2c5242e6af7abd5011dce14a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0758dc787b5041329dfe383947fa0ab9",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f98ee9b26db42e087c7dec99caf680c",
      "value": 20
     }
    },
    "88aa1c2e504a49b08c95dcca76b008ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "981d063cbad446a383c0f61a7fd8c122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88aa1c2e504a49b08c95dcca76b008ce",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf036d627906439383d8605417385c17",
      "value": 2
     }
    },
    "aade9e1a132a4fc694e1edc22f804690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa438f0e115e444d8935fb6d9fea1f32",
      "placeholder": "​",
      "style": "IPY_MODEL_52f2a93bd339471fb2174073ef900df7",
      "value": " 2/2 [00:06&lt;00:00,  3.02s/it]"
     }
    },
    "bb64f83fe1924062bf10c1f54c1e4fbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf036d627906439383d8605417385c17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d6978726be464ba8a3112e86ed39b75c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5767b48d8d4742949f60285bb20f353b",
      "placeholder": "​",
      "style": "IPY_MODEL_36547c9fb7b2492fa07194869fdf199e",
      "value": " 20/20 [02:32&lt;00:00, 11.70s/it]"
     }
    },
    "de932f98824d418f8665a94aab6b298e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34af9b8435ff44f7bc08fb24fd1cb1c1",
       "IPY_MODEL_780bec5f2c5242e6af7abd5011dce14a",
       "IPY_MODEL_d6978726be464ba8a3112e86ed39b75c"
      ],
      "layout": "IPY_MODEL_ff3d4b53295a4f9eacb7cafbc6adcf36"
     }
    },
    "e2926d00583842c488ecae1f437dcc02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa438f0e115e444d8935fb6d9fea1f32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb28f79da8f244d8bbc342183cabcbbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff3d4b53295a4f9eacb7cafbc6adcf36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
